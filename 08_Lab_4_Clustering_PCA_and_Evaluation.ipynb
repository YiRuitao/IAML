{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Clustering, PCA, and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we consider unsupervised learning in the form of clustering methods and principal component analysis (PCA), as well as more thorough performance evaluation of classifiers.\n",
    "\n",
    "All the datasets that you will need for this lab are located at the `./datasets` directory which is adjacent to this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from __future__ import division, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Clustering the landsat dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first consider clustering of the Landsat data. For information about the Landsat data you can read [this description](http://www.inf.ed.ac.uk/teaching/courses/dme/html/landsat.html). Since there are 6 classes in the data, it would be interesting to try clustering with k=6 centres..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "1. With pandas, read the csv dataset located at './datasets/landsat.csv'\n",
    "1. Split the data into the features `X` (pandas dataframe), and the labels `y` (easier to make it a numpy array)\n",
    "1. Give it a once over\n",
    "    * Get a feel for the size\n",
    "    * Check it looks ok\n",
    "    * Understand what the features are\n",
    "    * Plot the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "dp = os.path.join(os.getcwd(),'datasets','landsat.csv')\n",
    "landsat = pd.read_csv(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1_1</th>\n",
       "      <th>pixel1_2</th>\n",
       "      <th>pixel1_3</th>\n",
       "      <th>pixel1_4</th>\n",
       "      <th>pixel2_1</th>\n",
       "      <th>pixel2_2</th>\n",
       "      <th>pixel2_3</th>\n",
       "      <th>pixel2_4</th>\n",
       "      <th>pixel3_1</th>\n",
       "      <th>pixel3_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel7_4</th>\n",
       "      <th>pixel8_1</th>\n",
       "      <th>pixel8_2</th>\n",
       "      <th>pixel8_3</th>\n",
       "      <th>pixel8_4</th>\n",
       "      <th>pixel9_1</th>\n",
       "      <th>pixel9_2</th>\n",
       "      <th>pixel9_3</th>\n",
       "      <th>pixel9_4</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1_1  pixel1_2  pixel1_3  pixel1_4  pixel2_1  pixel2_2  pixel2_3  \\\n",
       "0      92.0     115.0     120.0      94.0      84.0     102.0     106.0   \n",
       "1      84.0     102.0     106.0      79.0      84.0     102.0     102.0   \n",
       "2      84.0     102.0     102.0      83.0      80.0     102.0     102.0   \n",
       "3      80.0     102.0     102.0      79.0      84.0      94.0     102.0   \n",
       "4      84.0      94.0     102.0      79.0      80.0      94.0      98.0   \n",
       "\n",
       "   pixel2_4  pixel3_1  pixel3_2  ...    pixel7_4  pixel8_1  pixel8_2  \\\n",
       "0      79.0      84.0     102.0  ...       104.0      88.0     121.0   \n",
       "1      83.0      80.0     102.0  ...       100.0      84.0     107.0   \n",
       "2      79.0      84.0      94.0  ...        87.0      84.0      99.0   \n",
       "3      79.0      80.0      94.0  ...        79.0      84.0      99.0   \n",
       "4      76.0      80.0     102.0  ...        79.0      84.0     103.0   \n",
       "\n",
       "   pixel8_3  pixel8_4  pixel9_1  pixel9_2  pixel9_3  pixel9_4  class  \n",
       "0     128.0     100.0      84.0     107.0     113.0      87.0      3  \n",
       "1     113.0      87.0      84.0      99.0     104.0      79.0      3  \n",
       "2     104.0      79.0      84.0      99.0     104.0      79.0      3  \n",
       "3     104.0      79.0      84.0     103.0     104.0      79.0      3  \n",
       "4     104.0      79.0      79.0     107.0     109.0      87.0      3  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landsat.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tip - don't get stuck on this, move on after 10 mins or so (it's not critical)*\n",
    "\n",
    "Plot a few datapoints. You'll need to understand and reshape the datapoints to do this. *Hint: try reading the [detailed description](http://www.inf.ed.ac.uk/teaching/courses/dme/html/satdoc.txt), it'll take you 2 minutes...`plt.imshow()` or `sns.heatmap()` (with an `ax.invert_yaxis()`) may also be handy ;)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ========== Question 1.3 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Read [this demonstration of k-means clustering assumptions](http://scikit-learn.org/0.17/auto_examples/cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py) from the sklearn documentation. Get a feel for how to create and fit a k-means object and what the different arguments do.\n",
    "\n",
    "Initialise a [k-means clustering](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) object with 6 clusters, and one other parameter that ensures you can reproduce your results (other arguments kept as default). Call the object `kmeans`. Use the `fit()` method to fit to the training data (`X` - the features of `landsat` created above)\n",
    "\n",
    "**Be careful to fit `X` - only the features - not the class labels!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how well did that work? Are the classes well separated and form 6 nice clusters? The sklearn documentation gives a great introduction to k-means [here](http://scikit-learn.org/stable/modules/clustering.html#k-means). It describes what the algorithm is trying to minimise - the squared difference between datapoints and their closest cluster centre - a.k.a. the **inertia**. Lower inertia implies a better fit.\n",
    "\n",
    "Since we have the true class labels in this case, we can use another metric: the [adjusted rand index](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation). Understand what it is and roughly how it is calculated (try the [mathematical formulation on sklearn](http://scikit-learn.org/stable/modules/clustering.html#mathematical-formulation) or [on wikipedia](https://en.wikipedia.org/wiki/Rand_index)).\n",
    "\n",
    "Print the `inertia` and the `adjusted_rand_score` of the kmeans object. The inertia is contained within the `kmeans` object you just fitted as a property. You need to use `y` and the cluster labels (another property of the `kmeans` object you just made), and are welcome to use the sklearn metrics function [adjusted_rand_score](http://scikit-learn.org/0.17/modules/generated/sklearn.metrics.adjusted_rand_score.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the counts of the labels within each cluster. If the clustering has worked well, and the labels are inticative of genuine difference in the data, we should expect each cluster to have one dominant label.\n",
    "\n",
    "Use `sns.countplot` on `kmeans.labels_` with a hue of `y` to get a plot that counts the number of instances within each cluster, and breaks them down by the class labels.\n",
    "\n",
    "Below the plot, comment on:\n",
    "1. How successful the clustering has been at separating data with different labels\n",
    "1. Focussing on clusters, which are the best?\n",
    "1. Focussing on labels, which are well identified by the clustering?\n",
    "1. Which labels are the hardest to determine by the data point cluster assignment?\n",
    "\n",
    "**Extension**: create a vector `y_labels` from `y` which has the names for the classes for a more interpretable plot with respect to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The landsat data is 36 dimensional, so we cannot visualise it, with respect to class, on a nice two dimensional plot. Additionally, as dimensionality increases, euclidean distance [becomes less meaningful](https://en.wikipedia.org/wiki/Curse_of_dimensionality#Distance_functions)...\n",
    "\n",
    "Perhaps if we found a lower dimensional subspace the data lies upon, we could more easily distinguish the datapoints..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the [PCA example](http://scikit-learn.org/0.17/auto_examples/decomposition/plot_pca_iris.html) in the sklearn documentation. For more information about PCA and decomposition in general check out the sklearn [user guide on decomposition](http://scikit-learn.org/stable/modules/decomposition.html#pca).\n",
    "\n",
    "We are going to project the data down to 2 dimensions and visualise it using PCA. \n",
    "\n",
    "1. Create `pca`, an instance of an [sklearn PCA object](http://scikit-learn.org/0.17/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA), setting n_components to 2. \n",
    "1. Create `X_2d` by using the pca method `fit_transform()` and supplying the features `X` to fit and transform to 2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the data! Use a scatterplot and colour the datapoints by their class. You'll find [this example](http://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html) very helpful to stea-I mean, adapt. \n",
    "\n",
    "Below the plot, comment on whether the data looks more or less seperable now. Do the data look like they will be confused by a k-means clustering in the same way now?\n",
    "\n",
    "**Extension**: Unless the data is somehow magically perfectly seperable, you may want to try and describe the space a little better than a scatterplot (bacause points are plotted on top of one another). Try and make a plot that clarifies the location of the classes. We're actually interested in where the **density** is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out whether it's easier to model the transformed data. Fit k-means to the transformed data and report the inertia and the adjusted rand index. Below, comment on whether it is better or worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blobs in the 2 dimensional plot do look quite gaussian...try another classifier on the 2d data and see if it can perform better. What about using 3 principal component? \n",
    "\n",
    "Maybe there are subclasses within each class? Maybe increasing the number of clusters will increase your `adjusted_rand_score`.\n",
    "\n",
    "Use the adjusted rand score for fair comparison. Why do you think it works better or worse? Discuss with your colleagues and lab tutors why you think you got better/worse/the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab prepared by Lawrence Murray and Chris Williams, November 2008; revised Athina Spiliopoulou Nov 2009; revised Sean Moran Nov 2011; revised Boris Mitrovic Oct 2013; revised and converted python by James Owers and Agamemnon Krasoulis Oct 2016"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
